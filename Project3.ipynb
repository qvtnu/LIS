{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import theano\n",
    "import lasagne\n",
    "import numpy as np\n",
    "from theano import tensor as T\n",
    "import time\n",
    "\n",
    "train = pd.read_hdf(\"train.h5\", \"train\")\n",
    "test = pd.read_hdf(\"test.h5\", \"test\")\n",
    "\n",
    "labelnumber=5   # 0 to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53461L, 100L)\n",
      "('feature selected new dimension is', 79)\n",
      "('train set size', (40792L, 79L), (40792L,))\n",
      "('Eval set size', (4532L, 79L), (4532L,))\n",
      "('Test set size', (8137L, 79L))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Miniconda\\lib\\site-packages\\ipykernel\\__main__.py:30: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "D:\\Program Files\\Miniconda\\lib\\site-packages\\ipykernel\\__main__.py:31: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "D:\\Program Files\\Miniconda\\lib\\site-packages\\ipykernel\\__main__.py:32: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "D:\\Program Files\\Miniconda\\lib\\site-packages\\ipykernel\\__main__.py:33: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# convert from dataframe to numpy array\n",
    "y_train = train.y.as_matrix()\n",
    "\n",
    "X_train = train.iloc[:,1:101].as_matrix()\n",
    "X_test= test.as_matrix()\n",
    "X = np.concatenate((X_train, X_test), 0)\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "# drop feature with too small standard deviation  (<0.005))\n",
    "drop_feature = np.where(X.std(axis=0)<0.005)\n",
    "X = np.delete(X, drop_feature, axis=1)\n",
    "\n",
    "dimension = X.shape[1]\n",
    "print (\"feature selected new dimension is\", int(dimension))\n",
    "\n",
    "#scale the X\n",
    "from sklearn.preprocessing import scale\n",
    "X = scale(X, axis=0)\n",
    "X_train = X [0:X_train.shape[0],:]\n",
    "X_test  = X [X_train.shape[0]:X.shape[0],:]\n",
    "\n",
    "# divide into train set and eval set\n",
    "num_sample = y_train.shape[0]\n",
    "\n",
    "# take 1/10 for evaluation\n",
    "num_eval = np.rint(num_sample/10)  \n",
    "num_train = num_sample-num_eval\n",
    "\n",
    "\n",
    "X_val = X_train[num_train:num_sample]\n",
    "X_train = X_train[0:num_train]\n",
    "y_val = y_train[num_train:num_sample].astype(int) \n",
    "y_train = y_train[0:num_train].astype(int) \n",
    "\n",
    "print('train set size', X_train.shape, y_train.shape)\n",
    "print('Eval set size', X_val.shape, y_val.shape)\n",
    "print('Test set size', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network 1: normal mlp(multilayer perceptron)\n",
    "def build_mlp(input_var=None):\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, dimension),\n",
    "                                     input_var=input_var)\n",
    "    \n",
    "    l_in_drop = lasagne.layers.DropoutLayer(l_in, p=0.2)\n",
    "    \n",
    "    l_hid1 = lasagne.layers.DenseLayer(\n",
    "        l_in_drop, num_units=400,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=lasagne.init.GlorotUniform())\n",
    "    \n",
    "    l_hid1_drop = lasagne.layers.DropoutLayer(l_hid1, p=0.5)\n",
    "\n",
    "    l_hid2 = lasagne.layers.DenseLayer(\n",
    "        l_hid1_drop, num_units=500,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "    l_hid2_drop = lasagne.layers.DropoutLayer(l_hid2, p=0.5)\n",
    "    \n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "        l_hid2_drop, num_units=5,\n",
    "        nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    \n",
    "    return l_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network 2:\n",
    "def build_custom_mlp(input_var=None, depth=2, width=800, drop_input=.2,\n",
    "                     drop_hidden=.5):\n",
    "    # Input layer and dropout (with shortcut `dropout` for `DropoutLayer`):\n",
    "    network = lasagne.layers.InputLayer(shape=(None, dimension),\n",
    "                                    input_var=input_var)\n",
    "    if drop_input:\n",
    "        network = lasagne.layers.dropout(network, p=drop_input)\n",
    "    # Hidden layers and dropout:\n",
    "    nonlin = lasagne.nonlinearities.rectify\n",
    "    for _ in range(depth):\n",
    "        network = lasagne.layers.DenseLayer(\n",
    "                network, width, nonlinearity=nonlin)\n",
    "        if drop_hidden:\n",
    "            network = lasagne.layers.dropout(network, p=drop_hidden)\n",
    "    # Output layer:\n",
    "    softmax = lasagne.nonlinearities.softmax\n",
    "    network = lasagne.layers.DenseLayer(network, 5, nonlinearity=softmax)\n",
    "    return network    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network 3: convolutional neural network\n",
    "def build_cnn(input_var=None):\n",
    "    network = lasagne.layers.InputLayer(shape=(None, dimension),\n",
    "                                        input_var=input_var)\n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "        network, num_filters=32, filter_size=(5, 5),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=lasagne.init.GlorotUniform())\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "        network, num_filters=32, filter_size=(5, 5),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "        lasagne.layers.dropout(network, p=.5),\n",
    "        num_units=256,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "        lasagne.layers.dropout(network, p=.5),\n",
    "        num_units=5,\n",
    "        nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare Theano variables for inputs and targets\n",
    "input_var = T.dmatrix('inputs')\n",
    "target_var = T.ivector('targets')\n",
    "\n",
    "# Create neural network model\n",
    "\n",
    "#network = build_mlp(input_var)\n",
    "\n",
    "network = build_custom_mlp(input_var, depth=2, width=800, drop_input=.2,\n",
    "                     drop_hidden=.5)\n",
    "\n",
    "\n",
    "prediction = lasagne.layers.get_output(network)\n",
    "\n",
    "# define loss function\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "loss = loss.mean()\n",
    "\n",
    "# update weights\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(\n",
    "        loss, params, learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "\n",
    "\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,\n",
    "                                                        target_var)\n",
    "test_loss = test_loss.mean()\n",
    "\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                  dtype=theano.config.floatX)\n",
    "\n",
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
    "predict_fn = theano.function([input_var], T.argmax(prediction, axis=1, keepdims=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 100 took 8.421s\n",
      "  training loss:\t\t0.290570\n",
      "  validation loss:\t\t0.167709\n",
      "  validation accuracy:\t\t94.18 %\n",
      "Epoch 2 of 100 took 8.441s\n",
      "  training loss:\t\t0.286835\n",
      "  validation loss:\t\t0.167292\n",
      "  validation accuracy:\t\t94.18 %\n",
      "Epoch 3 of 100 took 8.773s\n",
      "  training loss:\t\t0.290551\n",
      "  validation loss:\t\t0.167490\n",
      "  validation accuracy:\t\t94.24 %\n",
      "Epoch 4 of 100 took 8.812s\n",
      "  training loss:\t\t0.286029\n",
      "  validation loss:\t\t0.165276\n",
      "  validation accuracy:\t\t94.31 %\n",
      "Epoch 5 of 100 took 8.731s\n",
      "  training loss:\t\t0.286745\n",
      "  validation loss:\t\t0.165203\n",
      "  validation accuracy:\t\t94.33 %\n",
      "Epoch 6 of 100 took 8.683s\n",
      "  training loss:\t\t0.284585\n",
      "  validation loss:\t\t0.165836\n",
      "  validation accuracy:\t\t94.38 %\n",
      "Epoch 7 of 100 took 8.723s\n",
      "  training loss:\t\t0.286935\n",
      "  validation loss:\t\t0.165282\n",
      "  validation accuracy:\t\t94.36 %\n",
      "Epoch 8 of 100 took 8.724s\n",
      "  training loss:\t\t0.284481\n",
      "  validation loss:\t\t0.164933\n",
      "  validation accuracy:\t\t94.42 %\n",
      "Epoch 9 of 100 took 8.798s\n",
      "  training loss:\t\t0.283340\n",
      "  validation loss:\t\t0.163353\n",
      "  validation accuracy:\t\t94.51 %\n",
      "Epoch 10 of 100 took 8.711s\n",
      "  training loss:\t\t0.287366\n",
      "  validation loss:\t\t0.163114\n",
      "  validation accuracy:\t\t94.51 %\n",
      "Epoch 11 of 100 took 8.764s\n",
      "  training loss:\t\t0.280834\n",
      "  validation loss:\t\t0.163218\n",
      "  validation accuracy:\t\t94.53 %\n",
      "Epoch 12 of 100 took 8.765s\n",
      "  training loss:\t\t0.281117\n",
      "  validation loss:\t\t0.161855\n",
      "  validation accuracy:\t\t94.60 %\n",
      "Epoch 13 of 100 took 8.746s\n",
      "  training loss:\t\t0.284644\n",
      "  validation loss:\t\t0.160695\n",
      "  validation accuracy:\t\t94.62 %\n",
      "Epoch 14 of 100 took 8.665s\n",
      "  training loss:\t\t0.280930\n",
      "  validation loss:\t\t0.162098\n",
      "  validation accuracy:\t\t94.38 %\n",
      "Epoch 15 of 100 took 8.762s\n",
      "  training loss:\t\t0.277838\n",
      "  validation loss:\t\t0.161032\n",
      "  validation accuracy:\t\t94.53 %\n",
      "Epoch 16 of 100 took 8.774s\n",
      "  training loss:\t\t0.284903\n",
      "  validation loss:\t\t0.163159\n",
      "  validation accuracy:\t\t94.49 %\n",
      "Epoch 17 of 100 took 8.722s\n",
      "  training loss:\t\t0.279455\n",
      "  validation loss:\t\t0.159012\n",
      "  validation accuracy:\t\t94.67 %\n",
      "Epoch 18 of 100 took 8.734s\n",
      "  training loss:\t\t0.276784\n",
      "  validation loss:\t\t0.160296\n",
      "  validation accuracy:\t\t94.67 %\n",
      "Epoch 19 of 100 took 8.761s\n",
      "  training loss:\t\t0.278654\n",
      "  validation loss:\t\t0.158826\n",
      "  validation accuracy:\t\t94.67 %\n",
      "Epoch 20 of 100 took 8.764s\n",
      "  training loss:\t\t0.284947\n",
      "  validation loss:\t\t0.159701\n",
      "  validation accuracy:\t\t94.67 %\n",
      "Epoch 21 of 100 took 8.783s\n",
      "  training loss:\t\t0.275014\n",
      "  validation loss:\t\t0.158177\n",
      "  validation accuracy:\t\t94.67 %\n",
      "Epoch 22 of 100 took 8.708s\n",
      "  training loss:\t\t0.275447\n",
      "  validation loss:\t\t0.158457\n",
      "  validation accuracy:\t\t94.49 %\n",
      "Epoch 23 of 100 took 8.713s\n",
      "  training loss:\t\t0.277721\n",
      "  validation loss:\t\t0.156117\n",
      "  validation accuracy:\t\t94.49 %\n",
      "Epoch 24 of 100 took 8.836s\n",
      "  training loss:\t\t0.278907\n",
      "  validation loss:\t\t0.157992\n",
      "  validation accuracy:\t\t94.76 %\n",
      "Epoch 25 of 100 took 8.715s\n",
      "  training loss:\t\t0.274130\n",
      "  validation loss:\t\t0.156800\n",
      "  validation accuracy:\t\t94.53 %\n",
      "Epoch 26 of 100 took 8.798s\n",
      "  training loss:\t\t0.272346\n",
      "  validation loss:\t\t0.156113\n",
      "  validation accuracy:\t\t94.71 %\n",
      "Epoch 27 of 100 took 8.742s\n",
      "  training loss:\t\t0.275043\n",
      "  validation loss:\t\t0.156543\n",
      "  validation accuracy:\t\t94.76 %\n",
      "Epoch 28 of 100 took 8.759s\n",
      "  training loss:\t\t0.272972\n",
      "  validation loss:\t\t0.155554\n",
      "  validation accuracy:\t\t94.80 %\n",
      "Epoch 29 of 100 took 8.760s\n",
      "  training loss:\t\t0.271250\n",
      "  validation loss:\t\t0.154365\n",
      "  validation accuracy:\t\t94.76 %\n",
      "Epoch 30 of 100 took 8.751s\n",
      "  training loss:\t\t0.270589\n",
      "  validation loss:\t\t0.154734\n",
      "  validation accuracy:\t\t94.64 %\n",
      "Epoch 31 of 100 took 8.733s\n",
      "  training loss:\t\t0.275033\n",
      "  validation loss:\t\t0.154209\n",
      "  validation accuracy:\t\t94.71 %\n",
      "Epoch 32 of 100 took 8.761s\n",
      "  training loss:\t\t0.275324\n",
      "  validation loss:\t\t0.154041\n",
      "  validation accuracy:\t\t94.87 %\n",
      "Epoch 33 of 100 took 8.763s\n",
      "  training loss:\t\t0.266314\n",
      "  validation loss:\t\t0.153619\n",
      "  validation accuracy:\t\t94.80 %\n",
      "Epoch 34 of 100 took 8.716s\n",
      "  training loss:\t\t0.267346\n",
      "  validation loss:\t\t0.153028\n",
      "  validation accuracy:\t\t94.76 %\n",
      "Epoch 35 of 100 took 8.755s\n",
      "  training loss:\t\t0.270048\n",
      "  validation loss:\t\t0.153469\n",
      "  validation accuracy:\t\t94.78 %\n",
      "Epoch 36 of 100 took 8.784s\n",
      "  training loss:\t\t0.267903\n",
      "  validation loss:\t\t0.153240\n",
      "  validation accuracy:\t\t94.73 %\n",
      "Epoch 37 of 100 took 8.760s\n",
      "  training loss:\t\t0.269601\n",
      "  validation loss:\t\t0.152524\n",
      "  validation accuracy:\t\t94.87 %\n",
      "Epoch 38 of 100 took 8.675s\n",
      "  training loss:\t\t0.268008\n",
      "  validation loss:\t\t0.151989\n",
      "  validation accuracy:\t\t94.76 %\n",
      "Epoch 39 of 100 took 8.749s\n",
      "  training loss:\t\t0.271282\n",
      "  validation loss:\t\t0.151604\n",
      "  validation accuracy:\t\t94.87 %\n",
      "Epoch 40 of 100 took 8.747s\n",
      "  training loss:\t\t0.265382\n",
      "  validation loss:\t\t0.151628\n",
      "  validation accuracy:\t\t94.73 %\n",
      "Epoch 41 of 100 took 8.759s\n",
      "  training loss:\t\t0.267643\n",
      "  validation loss:\t\t0.150511\n",
      "  validation accuracy:\t\t94.89 %\n",
      "Epoch 42 of 100 took 8.793s\n",
      "  training loss:\t\t0.265893\n",
      "  validation loss:\t\t0.150179\n",
      "  validation accuracy:\t\t94.69 %\n",
      "Epoch 43 of 100 took 8.763s\n",
      "  training loss:\t\t0.265280\n",
      "  validation loss:\t\t0.150341\n",
      "  validation accuracy:\t\t94.73 %\n",
      "Epoch 44 of 100 took 8.753s\n",
      "  training loss:\t\t0.266243\n",
      "  validation loss:\t\t0.149569\n",
      "  validation accuracy:\t\t94.91 %\n",
      "Epoch 45 of 100 took 8.697s\n",
      "  training loss:\t\t0.262689\n",
      "  validation loss:\t\t0.149658\n",
      "  validation accuracy:\t\t94.98 %\n",
      "Epoch 46 of 100 took 8.728s\n",
      "  training loss:\t\t0.267352\n",
      "  validation loss:\t\t0.150900\n",
      "  validation accuracy:\t\t94.87 %\n",
      "Epoch 47 of 100 took 8.727s\n",
      "  training loss:\t\t0.262525\n",
      "  validation loss:\t\t0.147597\n",
      "  validation accuracy:\t\t94.98 %\n",
      "Epoch 48 of 100 took 8.650s\n",
      "  training loss:\t\t0.262450\n",
      "  validation loss:\t\t0.147993\n",
      "  validation accuracy:\t\t94.89 %\n",
      "Epoch 49 of 100 took 8.742s\n",
      "  training loss:\t\t0.261087\n",
      "  validation loss:\t\t0.148643\n",
      "  validation accuracy:\t\t94.96 %\n",
      "Epoch 50 of 100 took 8.733s\n",
      "  training loss:\t\t0.266988\n",
      "  validation loss:\t\t0.148897\n",
      "  validation accuracy:\t\t94.89 %\n",
      "Epoch 51 of 100 took 8.758s\n",
      "  training loss:\t\t0.257383\n",
      "  validation loss:\t\t0.147218\n",
      "  validation accuracy:\t\t94.84 %\n",
      "Epoch 52 of 100 took 8.659s\n",
      "  training loss:\t\t0.262162\n",
      "  validation loss:\t\t0.147965\n",
      "  validation accuracy:\t\t94.84 %\n",
      "Epoch 53 of 100 took 8.774s\n",
      "  training loss:\t\t0.261552\n",
      "  validation loss:\t\t0.147622\n",
      "  validation accuracy:\t\t94.87 %\n",
      "Epoch 54 of 100 took 8.743s\n",
      "  training loss:\t\t0.265959\n",
      "  validation loss:\t\t0.147413\n",
      "  validation accuracy:\t\t95.07 %\n",
      "Epoch 55 of 100 took 8.720s\n",
      "  training loss:\t\t0.259483\n",
      "  validation loss:\t\t0.147453\n",
      "  validation accuracy:\t\t94.89 %\n",
      "Epoch 56 of 100 took 8.739s\n",
      "  training loss:\t\t0.261059\n",
      "  validation loss:\t\t0.147574\n",
      "  validation accuracy:\t\t94.93 %\n",
      "Epoch 57 of 100 took 8.741s\n",
      "  training loss:\t\t0.258864\n",
      "  validation loss:\t\t0.147504\n",
      "  validation accuracy:\t\t94.87 %\n",
      "Epoch 58 of 100 took 8.745s\n",
      "  training loss:\t\t0.257702\n",
      "  validation loss:\t\t0.146516\n",
      "  validation accuracy:\t\t94.93 %\n",
      "Epoch 59 of 100 took 8.758s\n",
      "  training loss:\t\t0.261238\n",
      "  validation loss:\t\t0.145920\n",
      "  validation accuracy:\t\t94.98 %\n",
      "Epoch 60 of 100 took 8.724s\n",
      "  training loss:\t\t0.257583\n",
      "  validation loss:\t\t0.144561\n",
      "  validation accuracy:\t\t95.07 %\n",
      "Epoch 61 of 100 took 8.809s\n",
      "  training loss:\t\t0.258112\n",
      "  validation loss:\t\t0.146568\n",
      "  validation accuracy:\t\t94.91 %\n",
      "Epoch 62 of 100 took 8.762s\n",
      "  training loss:\t\t0.258664\n",
      "  validation loss:\t\t0.145444\n",
      "  validation accuracy:\t\t94.89 %\n",
      "Epoch 63 of 100 took 8.745s\n",
      "  training loss:\t\t0.259066\n",
      "  validation loss:\t\t0.145293\n",
      "  validation accuracy:\t\t94.96 %\n",
      "Epoch 64 of 100 took 8.738s\n",
      "  training loss:\t\t0.261448\n",
      "  validation loss:\t\t0.145620\n",
      "  validation accuracy:\t\t95.09 %\n",
      "Epoch 65 of 100 took 8.738s\n",
      "  training loss:\t\t0.256820\n",
      "  validation loss:\t\t0.143517\n",
      "  validation accuracy:\t\t95.31 %\n",
      "Epoch 66 of 100 took 8.763s\n",
      "  training loss:\t\t0.258148\n",
      "  validation loss:\t\t0.144502\n",
      "  validation accuracy:\t\t95.09 %\n",
      "Epoch 67 of 100 took 8.802s\n",
      "  training loss:\t\t0.256991\n",
      "  validation loss:\t\t0.144181\n",
      "  validation accuracy:\t\t95.04 %\n",
      "Epoch 68 of 100 took 8.789s\n",
      "  training loss:\t\t0.259108\n",
      "  validation loss:\t\t0.144152\n",
      "  validation accuracy:\t\t95.04 %\n",
      "Epoch 69 of 100 took 8.773s\n",
      "  training loss:\t\t0.245965\n",
      "  validation loss:\t\t0.144038\n",
      "  validation accuracy:\t\t95.13 %\n",
      "Epoch 70 of 100 took 8.743s\n",
      "  training loss:\t\t0.256632\n",
      "  validation loss:\t\t0.142926\n",
      "  validation accuracy:\t\t95.07 %\n",
      "Epoch 71 of 100 took 8.760s\n",
      "  training loss:\t\t0.251359\n",
      "  validation loss:\t\t0.143556\n",
      "  validation accuracy:\t\t95.18 %\n",
      "Epoch 72 of 100 took 8.736s\n",
      "  training loss:\t\t0.254798\n",
      "  validation loss:\t\t0.143545\n",
      "  validation accuracy:\t\t95.11 %\n",
      "Epoch 73 of 100 took 8.778s\n",
      "  training loss:\t\t0.250455\n",
      "  validation loss:\t\t0.144278\n",
      "  validation accuracy:\t\t95.07 %\n",
      "Epoch 74 of 100 took 8.765s\n",
      "  training loss:\t\t0.254836\n",
      "  validation loss:\t\t0.143776\n",
      "  validation accuracy:\t\t95.02 %\n",
      "Epoch 75 of 100 took 8.761s\n",
      "  training loss:\t\t0.255938\n",
      "  validation loss:\t\t0.142643\n",
      "  validation accuracy:\t\t95.13 %\n",
      "Epoch 76 of 100 took 8.768s\n",
      "  training loss:\t\t0.253695\n",
      "  validation loss:\t\t0.141252\n",
      "  validation accuracy:\t\t95.22 %\n",
      "Epoch 77 of 100 took 8.691s\n",
      "  training loss:\t\t0.255895\n",
      "  validation loss:\t\t0.143604\n",
      "  validation accuracy:\t\t95.24 %\n",
      "Epoch 78 of 100 took 8.801s\n",
      "  training loss:\t\t0.253921\n",
      "  validation loss:\t\t0.141305\n",
      "  validation accuracy:\t\t95.22 %\n",
      "Epoch 79 of 100 took 8.778s\n",
      "  training loss:\t\t0.251168\n",
      "  validation loss:\t\t0.142762\n",
      "  validation accuracy:\t\t95.18 %\n",
      "Epoch 80 of 100 took 8.683s\n",
      "  training loss:\t\t0.254286\n",
      "  validation loss:\t\t0.141622\n",
      "  validation accuracy:\t\t95.16 %\n",
      "Epoch 81 of 100 took 10.309s\n",
      "  training loss:\t\t0.251123\n",
      "  validation loss:\t\t0.143012\n",
      "  validation accuracy:\t\t95.13 %\n",
      "Epoch 82 of 100 took 11.377s\n",
      "  training loss:\t\t0.249181\n",
      "  validation loss:\t\t0.142986\n",
      "  validation accuracy:\t\t95.16 %\n",
      "Epoch 83 of 100 took 11.425s\n",
      "  training loss:\t\t0.252742\n",
      "  validation loss:\t\t0.141706\n",
      "  validation accuracy:\t\t95.36 %\n",
      "Epoch 84 of 100 took 11.369s\n",
      "  training loss:\t\t0.249836\n",
      "  validation loss:\t\t0.142190\n",
      "  validation accuracy:\t\t95.18 %\n",
      "Epoch 85 of 100 took 11.389s\n",
      "  training loss:\t\t0.247140\n",
      "  validation loss:\t\t0.141235\n",
      "  validation accuracy:\t\t95.22 %\n",
      "Epoch 86 of 100 took 11.399s\n",
      "  training loss:\t\t0.250335\n",
      "  validation loss:\t\t0.141207\n",
      "  validation accuracy:\t\t95.22 %\n",
      "Epoch 87 of 100 took 8.947s\n",
      "  training loss:\t\t0.249439\n",
      "  validation loss:\t\t0.139369\n",
      "  validation accuracy:\t\t95.27 %\n",
      "Epoch 88 of 100 took 8.738s\n",
      "  training loss:\t\t0.251570\n",
      "  validation loss:\t\t0.140468\n",
      "  validation accuracy:\t\t95.56 %\n",
      "Epoch 89 of 100 took 8.752s\n",
      "  training loss:\t\t0.246332\n",
      "  validation loss:\t\t0.139945\n",
      "  validation accuracy:\t\t95.33 %\n",
      "Epoch 90 of 100 took 8.704s\n",
      "  training loss:\t\t0.246499\n",
      "  validation loss:\t\t0.141504\n",
      "  validation accuracy:\t\t95.22 %\n",
      "Epoch 91 of 100 took 8.642s\n",
      "  training loss:\t\t0.249722\n",
      "  validation loss:\t\t0.139034\n",
      "  validation accuracy:\t\t95.33 %\n",
      "Epoch 92 of 100 took 8.670s\n",
      "  training loss:\t\t0.251161\n",
      "  validation loss:\t\t0.138833\n",
      "  validation accuracy:\t\t95.40 %\n",
      "Epoch 93 of 100 took 8.476s\n",
      "  training loss:\t\t0.251835\n",
      "  validation loss:\t\t0.139403\n",
      "  validation accuracy:\t\t95.47 %\n",
      "Epoch 94 of 100 took 8.332s\n",
      "  training loss:\t\t0.252302\n",
      "  validation loss:\t\t0.138909\n",
      "  validation accuracy:\t\t95.38 %\n",
      "Epoch 95 of 100 took 8.349s\n",
      "  training loss:\t\t0.243298\n",
      "  validation loss:\t\t0.139914\n",
      "  validation accuracy:\t\t95.33 %\n",
      "Epoch 96 of 100 took 8.322s\n",
      "  training loss:\t\t0.247997\n",
      "  validation loss:\t\t0.138913\n",
      "  validation accuracy:\t\t95.31 %\n",
      "Epoch 97 of 100 took 8.392s\n",
      "  training loss:\t\t0.244797\n",
      "  validation loss:\t\t0.140486\n",
      "  validation accuracy:\t\t95.16 %\n",
      "Epoch 98 of 100 took 8.361s\n",
      "  training loss:\t\t0.241458\n",
      "  validation loss:\t\t0.140917\n",
      "  validation accuracy:\t\t95.20 %\n",
      "Epoch 99 of 100 took 8.355s\n",
      "  training loss:\t\t0.247688\n",
      "  validation loss:\t\t0.138777\n",
      "  validation accuracy:\t\t95.24 %\n",
      "Epoch 100 of 100 took 8.318s\n",
      "  training loss:\t\t0.247958\n",
      "  validation loss:\t\t0.139400\n",
      "  validation accuracy:\t\t95.20 %\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "batchsize = 500\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train, y_train, 500, shuffle=True):\n",
    "        inputs, targets = batch\n",
    "        train_err += train_fn(inputs, targets)\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    \n",
    "    for batch in iterate_minibatches(X_val, y_val, 500, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err, acc = val_fn(inputs, targets)\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "        val_batches += 1\n",
    "\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Prediction tset size', (8137L,))\n"
     ]
    }
   ],
   "source": [
    "y_test = predict_fn(X_test)\n",
    "print('Prediction tset size', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"sample.csv\")\n",
    "sub['y'] = y_test\n",
    "sub.head()\n",
    "sub.to_csv('mlp_800_800_200epoch.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
