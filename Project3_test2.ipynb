{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import theano\n",
    "import lasagne\n",
    "import numpy as np\n",
    "from theano import tensor as T\n",
    "import time\n",
    "\n",
    "train = pd.read_hdf(\"train.h5\", \"train\")\n",
    "test = pd.read_hdf(\"test.h5\", \"test\")\n",
    "\n",
    "labelnumber=5   # 0 to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53461, 100)\n",
      "feature selected new dimension is 79\n",
      "train set size (40792, 79) (40792,)\n",
      "Eval set size (4532, 79) (4532,)\n",
      "Test set size (8137, 79)\n",
      "train2 (45324, 79) (45324,)\n",
      "training set (45324, 80)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:184: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:35: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:36: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:37: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:38: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# convert from dataframe to numpy array\n",
    "y_train = train.y.as_matrix()\n",
    "\n",
    "X_train = train.iloc[:,1:101].as_matrix()\n",
    "X_test= test.as_matrix()\n",
    "X = np.concatenate((X_train, X_test), 0)\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "# drop feature with too small standard deviation  (<0.005))\n",
    "drop_feature = np.where(X.std(axis=0)<0.005)\n",
    "X = np.delete(X, drop_feature, axis=1)\n",
    "\n",
    "dimension = X.shape[1]\n",
    "print (\"feature selected new dimension is\", int(dimension))\n",
    "\n",
    "#scale the X\n",
    "from sklearn.preprocessing import scale\n",
    "X = scale(X, axis=0)\n",
    "X_train = X [0:X_train.shape[0],:]\n",
    "X_test  = X [X_train.shape[0]:X.shape[0],:]\n",
    "\n",
    "# divide into train set and eval set\n",
    "num_sample = y_train.shape[0]\n",
    "\n",
    "# take 1/10 for evaluation\n",
    "num_eval = np.rint(num_sample/10)  \n",
    "num_train = num_sample-num_eval\n",
    "\n",
    "X_train2 = X_train[:]\n",
    "y_train2 = y_train[:]\n",
    "\n",
    "training =np.concatenate((np.matrix(y_train2).T, X_train2), 1)\n",
    "\n",
    "X_val = X_train[num_train:num_sample]\n",
    "X_train = X_train[0:num_train]\n",
    "y_val = y_train[num_train:num_sample].astype(int) \n",
    "y_train = y_train[0:num_train].astype(int) \n",
    "\n",
    "print('train set size', X_train.shape, y_train.shape)\n",
    "print('Eval set size', X_val.shape, y_val.shape)\n",
    "print('Test set size', X_test.shape)\n",
    "print('train2', X_train2.shape, y_train2.shape)\n",
    "print('training set',training.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network 1: normal mlp(multilayer perceptron)\n",
    "def build_mlp(input_var=None):\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, dimension),\n",
    "                                     input_var=input_var)\n",
    "    \n",
    "    l_in_drop = lasagne.layers.DropoutLayer(l_in, p=0.5)\n",
    "    \n",
    "    l_hid1 = lasagne.layers.DenseLayer(\n",
    "        l_in_drop, num_units=800,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=lasagne.init.GlorotUniform())\n",
    "    \n",
    "    l_hid1_drop = lasagne.layers.DropoutLayer(l_hid1, p=0.5)\n",
    "\n",
    "    l_hid2 = lasagne.layers.DenseLayer(\n",
    "        l_hid1_drop, num_units=800,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "    l_hid2_drop = lasagne.layers.DropoutLayer(l_hid2, p=0.5)\n",
    "    \n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "        l_hid2_drop, num_units=5,\n",
    "        nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    \n",
    "    return l_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network 2:\n",
    "def build_custom_mlp(input_var=None, depth=5, width=800, drop_input=.2,\n",
    "                     drop_hidden=.5):\n",
    "    # Input layer and dropout (with shortcut `dropout` for `DropoutLayer`):\n",
    "    network = lasagne.layers.InputLayer(shape=(None, dimension),\n",
    "                                    input_var=input_var)\n",
    "    if drop_input:\n",
    "        network = lasagne.layers.dropout(network, p=drop_input)\n",
    "    # Hidden layers and dropout:\n",
    "    nonlin = lasagne.nonlinearities.LeakyRectify(0.001)\n",
    "    for _ in range(depth):\n",
    "        network = lasagne.layers.DenseLayer(\n",
    "                network, width, nonlinearity=nonlin)\n",
    "        if drop_hidden:\n",
    "            network = lasagne.layers.dropout(network, p=drop_hidden)\n",
    "    # Output layer:\n",
    "    softmax = lasagne.nonlinearities.softmax\n",
    "    network = lasagne.layers.DenseLayer(network, 5, nonlinearity=softmax)\n",
    "    return network    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network 2 copy:\n",
    "def build_custom_mlp(input_var=None, nonlinOrder = [0,1,0], width=[500,500,500], drop_input=.2,\n",
    "                     drop_hidden=.5):\n",
    "    # Input layer and dropout (with shortcut `dropout` for `DropoutLayer`):\n",
    "    network = lasagne.layers.InputLayer(shape=(None, dimension),\n",
    "                                    input_var=input_var)\n",
    "    if drop_input:\n",
    "        network = lasagne.layers.dropout(network, p=drop_input)\n",
    "    # Hidden layers and dropout:\n",
    "    nonlin = [lasagne.nonlinearities.rectify,lasagne.nonlinearities.tanh, lasagne.nonlinearities.ScaledTanh,\n",
    "              lasagne.nonlinearities.softmax\n",
    "              ,lasagne.nonlinearities.LeakyRectify(0.1)]\n",
    "    for i in range(len(width)):\n",
    "        network = lasagne.layers.DenseLayer(\n",
    "                network, width[i], nonlinearity=nonlin[nonlinOrder[i]])\n",
    "        if drop_hidden:\n",
    "            network = lasagne.layers.dropout(network, p=drop_hidden)\n",
    "    # Output layer:\n",
    "    softmax = lasagne.nonlinearities.softmax\n",
    "    network = lasagne.layers.DenseLayer(network, 5, nonlinearity=softmax)\n",
    "    return network    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# network 3: convolutional neural network\n",
    "def build_cnn(input_var=None):\n",
    "    network = lasagne.layers.InputLayer(shape=(None, dimension),\n",
    "                                        input_var=input_var)\n",
    "    network = lasagne.layers.Conv1DLayer(\n",
    "        network, num_filters=32, filter_size=10,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=lasagne.init.GlorotUniform())\n",
    "    network = lasagne.layers.MaxPool1DLayer(network, pool_size=2)\n",
    "    network = lasagne.layers.Conv1DLayer(\n",
    "        network, num_filters=32, filter_size=10,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    network = lasagne.layers.MaxPool1DLayer(network, pool_size=2)\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "        lasagne.layers.dropout(network, p=.5),\n",
    "        num_units=256,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "        lasagne.layers.dropout(network, p=.5),\n",
    "        num_units=5,\n",
    "        nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tried to create a 1D convolution layer with input shape (None, 79). Expected 3 input dimensions (batchsize, channels, 1 spatial dimensions).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fcfbcb36bdfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#network = build_custom_mlp(input_var, nonlinOrder = [1,0], width=[1000,1000], drop_input=.2, drop_hidden=.5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-de673abbee96>\u001b[0m in \u001b[0;36mbuild_cnn\u001b[0;34m(input_var)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_filters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mnonlinearity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlasagne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonlinearities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectify\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         W=lasagne.init.GlorotUniform())\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool1DLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     network = lasagne.layers.Conv1DLayer(\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/lasagne/layers/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, incoming, num_filters, filter_size, stride, pad, untie_biases, W, b, nonlinearity, flip_filters, convolution, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m                                           \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muntie_biases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                                           \u001b[0mnonlinearity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflip_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                                           **kwargs)\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvolution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/lasagne/layers/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, incoming, num_filters, filter_size, stride, pad, untie_biases, W, b, nonlinearity, flip_filters, n, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m                              \u001b[0;34m\"input shape %r. Expected %d input dimensions \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                              \u001b[0;34m\"(batchsize, channels, %d spatial dimensions).\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                              (n, self.input_shape, n+2, n))\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_filters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tried to create a 1D convolution layer with input shape (None, 79). Expected 3 input dimensions (batchsize, channels, 1 spatial dimensions)."
     ]
    }
   ],
   "source": [
    "# Prepare Theano variables for inputs and targets\n",
    "\n",
    "#introduce regularization\n",
    "from lasagne.regularization import regularize_layer_params, l1, l2\n",
    "penalty_rate = 1e-2;\n",
    "\n",
    "input_var = T.dmatrix('inputs')\n",
    "target_var = T.ivector('targets')\n",
    "\n",
    "# Create neural network model\n",
    "\n",
    "#network = build_mlp(input_var)\n",
    "\n",
    "#network = build_custom_mlp(input_var, nonlinOrder = [1,0], width=[1000,1000], drop_input=.2, drop_hidden=.5)\n",
    "\n",
    "network = build_cnn(input_var)\n",
    "\n",
    "prediction = lasagne.layers.get_output(network)\n",
    "\n",
    "#add regularization\n",
    "penalty = regularize_layer_params(network, l1) * penalty_rate\n",
    "# define loss function\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var) + penalty\n",
    "loss = loss.mean()\n",
    "\n",
    "# update weights\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(\n",
    "        loss, params, learning_rate=0.1, momentum=0.9)\n",
    "\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "\n",
    "test_penalty = regularize_layer_params(network, l1) * penalty_rate\n",
    "\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(test_prediction, target_var) + test_penalty\n",
    "test_loss = test_loss.mean()\n",
    "\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                  dtype=theano.config.floatX)\n",
    "\n",
    "train_fn = theano.function([input_var, target_var], loss, updates=updates, allow_input_downcast=True)\n",
    "val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
    "predict_fn = theano.function([input_var], T.argmax(prediction, axis=1, keepdims=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 100 took 5.371s\n",
      "  training loss:\t\t1.765432\n",
      "  validation loss:\t\t0.868533\n",
      "  validation accuracy:\t\t81.11 %\n",
      "Epoch 2 of 100 took 3.916s\n",
      "  training loss:\t\t0.481481\n",
      "  validation loss:\t\t0.797451\n",
      "  validation accuracy:\t\t81.76 %\n",
      "Epoch 3 of 100 took 3.757s\n",
      "  training loss:\t\t0.024691\n",
      "  validation loss:\t\t0.757378\n",
      "  validation accuracy:\t\t82.62 %\n",
      "Epoch 4 of 100 took 3.261s\n",
      "  training loss:\t\t0.000000\n",
      "  validation loss:\t\t0.727319\n",
      "  validation accuracy:\t\t83.38 %\n",
      "Epoch 5 of 100 took 4.299s\n",
      "  training loss:\t\t0.000000\n",
      "  validation loss:\t\t0.700363\n",
      "  validation accuracy:\t\t84.31 %\n",
      "Epoch 6 of 100 took 3.741s\n",
      "  training loss:\t\t0.000000\n",
      "  validation loss:\t\t0.685488\n",
      "  validation accuracy:\t\t84.84 %\n",
      "Epoch 7 of 100 took 4.227s\n",
      "  training loss:\t\t0.000000\n",
      "  validation loss:\t\t0.667261\n",
      "  validation accuracy:\t\t85.18 %\n",
      "Epoch 8 of 100 took 3.561s\n",
      "  training loss:\t\t0.000000\n",
      "  validation loss:\t\t0.647158\n",
      "  validation accuracy:\t\t85.47 %\n",
      "Epoch 9 of 100 took 3.693s\n",
      "  training loss:\t\t0.000000\n",
      "  validation loss:\t\t0.634415\n",
      "  validation accuracy:\t\t85.76 %\n",
      "Epoch 10 of 100 took 3.768s\n",
      "  training loss:\t\t0.000000\n",
      "  validation loss:\t\t0.616145\n",
      "  validation accuracy:\t\t86.44 %\n",
      "Epoch 11 of 100 took 4.046s\n",
      "  training loss:\t\t0.000000\n",
      "  validation loss:\t\t0.604089\n",
      "  validation accuracy:\t\t86.84 %\n",
      "Epoch 12 of 100 took 4.389s\n",
      "  training loss:\t\t0.000000\n",
      "  validation loss:\t\t0.592247\n",
      "  validation accuracy:\t\t87.00 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2317d37bdf77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mtrain_err\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtrain_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    912\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/theano/tensor/blas.py\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inp, out)\u001b[0m\n\u001b[1;32m   1821\u001b[0m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m             \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalar\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m             \u001b[0;31m# The error raised by numpy has no shape information, we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "batchsize = 500\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    if epoch == 0:\n",
    "    #if 1:\n",
    "        np.random.shuffle(training)\n",
    "        X_train3 = training[0:int(len(training)*0.9),1:]\n",
    "        y_train3 = training[0:int(len(training)*0.9),0]\n",
    "        y_train3 = np.array(y_train3)\n",
    "        X_val3 = training[int(len(training)*0.9):len(training),1:]\n",
    "        y_val3 = training[int(len(training)*0.9):len(training),0]\n",
    "        y_val3 = np.array(y_val3)\n",
    "\n",
    "    train_err = np.int64(0)\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(np.array(X_train3),np.array(y_train3.T[0]), 500, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        tmp = train_fn(inputs, targets)\n",
    "        train_err += tmp.astype(np.int32) \n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    \n",
    "    for batch in iterate_minibatches(np.array(X_val3),np.array(y_val3.T[0]), 500, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        #tmp = val_fn(inputs.astype(np.int32), targets.astype(np.int32))\n",
    "        tmp = val_fn(inputs, targets.astype(np.int32))\n",
    "        err, acc = tmp\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "        val_batches += 1\n",
    "\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction tset size (8137,)\n"
     ]
    }
   ],
   "source": [
    "y_test = predict_fn(X_test)\n",
    "print('Prediction tset size', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8137, 79)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"sample.csv\")\n",
    "sub['y'] = y_test\n",
    "sub.head()\n",
    "sub.to_csv('22_tanh.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
